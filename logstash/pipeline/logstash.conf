# logstash/pipeline/logstash.conf
# ------------------------------------------------------------
# Purpose
#   - Read local demo log files bind-mounted into the container at /logs
#   - Parse Nginx *access* lines into ECS fields via a grok filter
#   - Parse Nginx *error* lines (basic structure + optional client/server/request/host fields)
#   - Send to Elasticsearch using credentials from environment
#
# Notes
#   - Works with the docker-compose you’re running (ES + Logstash + Kibana)
#   - Index names:
#       nginx_access-YYYY.MM.DD
#       nginx_error-YYYY.MM.DD
#   - ECS compatibility is v8 by default in LS 8, so fields below match ECS.
# ------------------------------------------------------------

input {
  # Access log
  file {
    id                => "nginx-access"
    path              => ["/logs/access.log"]
    start_position    => "beginning"
    sincedb_path      => "/usr/share/logstash/data/sincedb-access"
    # Important for a demo: re-read if files are recreated/truncated
    file_completed_action => "log"
    codec => plain { charset => "UTF-8" }
    mode => "read"
  }

  # Error log
  file {
    id                => "nginx-error"
    path              => ["/logs/error.log"]
    start_position    => "beginning"
    sincedb_path      => "/usr/share/logstash/data/sincedb-error"
    file_completed_action => "log"
    codec => plain { charset => "UTF-8" }
    mode => "read"
  }
}

filter {
  ###############################
  # ACCESS LOGS
  ###############################
  if [log][file][path] =~ /access\.log$/ or [path] =~ /access\.log$/ {
    mutate { add_tag => ["nginx_access"] }

    # Example access line you’re generating:
    # 127.0.0.1 - - [27/Aug/2025:06:46:39 +0000] "GET /hello HTTP/1.1" 200 123 "-" "curl/8.1.0" 0.045
    grok {
      tag_on_failure => ["_grokparsefailure_access"]
      match => {
        "message" => [
          # method, URL, version, status, bytes, referrer, ua, optional duration
          '%{IP:client.ip} %{DATA:ident} %{DATA:user.name} \[%{HTTPDATE:nginx.access.time}\] "(?<http.request.method>[A-Z]+) %{DATA:url.original} HTTP/%{NUMBER:http.version}" %{NUMBER:http.response.status_code:int} (?:%{NUMBER:http.response.body.bytes:int}|-) "(?:-|%{DATA:http.request.referrer})" "(?:-|%{DATA:user_agent.original})"(?: %{NUMBER:event.duration:float})?'
        ]
      }
    }

    # Normalize timestamp (@timestamp from nginx.access.time)
    date {
      match  => ["nginx.access.time", "dd/MMM/YYYY:HH:mm:ss Z", "EEE MMM dd HH:mm:ss Z YYYY"]
      target => "@timestamp"
      # timezone will be read from date string (+0000), so no explicit timezone needed
    }

    # If duration was present as seconds (e.g., 0.045), convert to microseconds for ECS event.duration (in ns by spec).
    # Here we keep seconds in event.duration_sec for readability and write event.duration (ns) to follow ECS strictly.
    ruby {
      code => '
        if event.get("event") && event.get("event")["duration"].is_a?(Float)
          secs = event.get("event")["duration"]
          event.set("[event][duration_sec]", secs)
          event.set("[event][duration]", (secs * 1_000_000_000).to_i)
        end
      '
    }

    # Map “-” to nils, tidy up
    mutate {
      gsub => [
        "http.request.referrer", '^-$', "",
        "user_agent.original",   '^-$', ""
      ]
      remove_field => ["ident","nginx.access.time"]
    }
  }

  ###############################
  # ERROR LOGS
  ###############################
  if [log][file][path] =~ /error\.log$/ or [path] =~ /error\.log$/ {
    mutate { add_tag => ["nginx_error"] }

    # Minimal structure first:
    # [error] 123#123: *1 message...
    grok {
      tag_on_failure => ["_grokparsefailure_error"]
      match => {
        "message" => [
          '^\[%{LOGLEVEL:log.level}\]\s+%{NUMBER:process.pid:int}#%{NUMBER:process.thread.id:int}:\s*(?:\*%{NUMBER:nginx.error.connection_id:int}\s*)?%{GREEDYDATA:message}'
        ]
      }
    }

    # Pull common structured bits if present in the message (optional)
    grok {
      break_on_match => false
      tag_on_failure => ["_grokparsefailure_error_extras"]
      match => {
        "message" => [
          'client:\s*%{IP:client.ip}',
          'server:\s*%{DATA:server.address}',
          'request:\s*"%{WORD:http.request.method}\s+%{DATA:url.original}\s+HTTP/%{NUMBER:http.version}"',
          'host:\s*"%{DATA:server.domain}"'
        ]
      }
    }
  }
}

output {
  # Send everything to Elasticsearch; split indexes by tag
  if "nginx_access" in [tags] {
    elasticsearch {
      hosts    => ["http://elasticsearch:9200"]
      user     => "elastic"
      password => "${ELASTIC_PASSWORD}"
      index    => "nginx_access-%{+YYYY.MM.dd}"
    }
  } else if "nginx_error" in [tags] {
    elasticsearch {
      hosts    => ["http://elasticsearch:9200"]
      user     => "elastic"
      password => "${ELASTIC_PASSWORD}"
      index    => "nginx_error-%{+YYYY.MM.dd}"
    }
  } else {
    # Fallback (shouldn’t really be used in this demo)
    elasticsearch {
      hosts    => ["http://elasticsearch:9200"]
      user     => "elastic"
      password => "${ELASTIC_PASSWORD}"
      index    => "misc-%{+YYYY.MM.dd}"
    }
  }

  # Also to stdout for quick visual checks in `docker compose logs -f logstash`
  stdout { codec => rubydebug }
}
