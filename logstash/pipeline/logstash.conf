# ========================= Inputs =========================
input {
  # Tail Nginx access log (container path /logs maps to your project ./logs)
  file {
    id => "nginx_access"
    path => ["/logs/access.log"]          # file to watch (tail)
    start_position => "beginning"         # on first run, read from start
    sincedb_path => "/usr/share/logstash/data/sincedb_access"
    mode => "tail"                        # follow new lines like `tail -f`
    tags => ["nginx_access"]              # mark events so we can branch later
  }

  # Tail Nginx error log
  file {
    id => "nginx_error"
    path => ["/logs/error.log"]
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb_error"
    mode => "tail"
    tags => ["nginx_error"]
  }
}

# ========================= Filters =========================
filter {
  # -------- Access log parsing --------
  if "nginx_access" in [tags] {
    grok {
      # Example line:
      # 127.0.0.1 - - [01/Sep/2025:13:21:32 +0000] "GET /hello HTTP/1.1" 200 123 "-" "curl/8.1.0" 0.045
      match => { "message" => [
        '%{IPORHOST:clientip} %{DATA:ident} %{DATA:auth} \[%{HTTPDATE:timestamp}\] "%{WORD:verb} %{DATA:request} HTTP/%{NUMBER:httpversion}" %{NUMBER:response:int} (?:%{NUMBER:bytes:int}|-) "%{DATA:referrer}" "%{DATA:agent}" %{NUMBER:request_time:float}'
      ] }
      tag_on_failure => ["_grokparsefailure_access"]  # if the pattern misses
    }

    # Convert the textual timestamp into @timestamp (Logstash event time)
    date {
      match => ["timestamp","dd/MMM/YYYY:HH:mm:ss Z"]
      target => "@timestamp"
      remove_field => ["timestamp"]
    }
  }

  # -------- Error log parsing --------
  if "nginx_error" in [tags] {
    grok {
      # Example line:
      # [error] 123#123: *1 open() "/var/www/html/missing.html" failed ... request: "GET /missing.html HTTP/1.1"
      match => { "message" => [
        '\[%{LOGLEVEL:level}\] %{NUMBER:pid:int}#%{NUMBER:tid:int}: \*%{NUMBER:conn:int} %{GREEDYDATA:errmsg}, client: %{IPORHOST:client}, server: %{DATA:server}, request: "%{WORD:verb} %{DATA:request} HTTP/%{NUMBER:httpversion}", host: "%{DATA:host}"'
      ] }
      tag_on_failure => ["_grokparsefailure_error"]
    }

    # Align with ECS naming (Kibana expects log.level)
    mutate { rename => { "level" => "log.level" } }
  }

  # Common enrichment for both streams
  mutate { add_field => { "ingest.source" => "mini-elk" } }
}

# ========================= Outputs =========================
output {
  # Access events â†’ daily index
  if "nginx_access" in [tags] {
    elasticsearch {
      hosts    => ["http://elasticsearch:9200"]   # service name inside compose
      user     => "elastic"
      password => "${ELASTIC_PASSWORD}"           # pulled from container env
      index    => "nginx_access-%{+YYYY.MM.dd}"   # time-partitioned
    }
  }

  # Error events â†’ daily index
  if "nginx_error" in [tags] {
    elasticsearch {
      hosts    => ["http://elasticsearch:9200"]
      user     => "elastic"
      password => "${ELASTIC_PASSWORD}"
      index    => "nginx_error-%{+YYYY.MM.dd}"
    }
  }

  # Mirror to stdout for quick troubleshooting (docker logs)
  stdout { codec => rubydebug }
}
